{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 :: Stratified Sampling\n",
    "\n",
    "**Objectives:**\n",
    "* split the data into training and test sets, stratified by the major categories: AGE, GT, ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load common.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Commonly used constants.\n",
    "\n",
    "slides = [\n",
    "    'B02_D1', 'B02_E1', 'B03_C2', 'B03_D2', 'B04_D1',\n",
    "    'B04_E1', 'B05_D2', 'B05_E2', 'B06_E1', 'B07_C2',\n",
    "    'N02_C1', 'N02_D1', 'N03_C2', 'N03_D2', 'N04_D1',\n",
    "    'N04_E1', 'N05_C2', 'N05_D2', 'N06_D2', 'N07_C1']\n",
    "\n",
    "GT = 'GT'\n",
    "YEN = 'AB1_StdDev_Yen'\n",
    "REGION = 'Region_predict'\n",
    "ASTROCYTE = 'astrocyte'\n",
    "NEURON = 'neuron'\n",
    "INTERNEURON = 'interneuron'\n",
    "AGE = 'age'\n",
    "DAYS = 'age_days'\n",
    "MONTHS = 'age_months'\n",
    "AGE_GT ='age_GT'\n",
    "SAMPLE_ID = 'sampleID'\n",
    "SPOT_UID = 'spot_UID'\n",
    "\n",
    "# The merged data file in Parquet format.\n",
    "\n",
    "parquet = '/media/tmo/data/work/datasets/02_ST/parquet/'\n",
    "st_full = parquet + 'st_full'\n",
    "\n",
    "def read_full(path=st_full):\n",
    "    return pd.read_parquet(st_full)\n",
    "\n",
    "def enrich(full):\n",
    "    # Add age column (young, old)\n",
    "    full[AGE] = np.where(full[MONTHS] < 10, 'young', 'old')\n",
    "    # Add combined column age_GT.\n",
    "    full[AGE_GT] = full[[AGE, GT]].apply(lambda x: '_'.join(x), axis=1)\n",
    "    \n",
    "    return full\n",
    "\n",
    "def read_enriched(path=st_full):\n",
    "    return enrich(read_full(path))\n",
    "    \n",
    "# TODO\n",
    "# * add 'coarse_region' that joins regions with <500 entries in them into one region OTHER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = read_enriched()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = full[[SPOT_UID]]\n",
    "y = full[[AGE]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y[AGE], random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9294 entries, 199 to 134\n",
      "Data columns (total 1 columns):\n",
      "spot_UID    9294 non-null object\n",
      "dtypes: object(1)\n",
      "memory usage: 145.2+ KB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "young    4776\n",
       "old      4518\n",
       "Name: age, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[AGE].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Split arrays or matrices into random train and test subsets\n",
       "\n",
       "Quick utility that wraps input validation and\n",
       "``next(ShuffleSplit().split(X, y))`` and application to input data\n",
       "into a single call for splitting (and optionally subsampling) data in a\n",
       "oneliner.\n",
       "\n",
       "Read more in the :ref:`User Guide <cross_validation>`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "*arrays : sequence of indexables with same length / shape[0]\n",
       "    Allowed inputs are lists, numpy arrays, scipy-sparse\n",
       "    matrices or pandas dataframes.\n",
       "\n",
       "test_size : float, int, or None (default is None)\n",
       "    If float, should be between 0.0 and 1.0 and represent the\n",
       "    proportion of the dataset to include in the test split. If\n",
       "    int, represents the absolute number of test samples. If None,\n",
       "    the value is automatically set to the complement of the train size.\n",
       "    If train size is also None, test size is set to 0.25.\n",
       "\n",
       "train_size : float, int, or None (default is None)\n",
       "    If float, should be between 0.0 and 1.0 and represent the\n",
       "    proportion of the dataset to include in the train split. If\n",
       "    int, represents the absolute number of train samples. If None,\n",
       "    the value is automatically set to the complement of the test size.\n",
       "\n",
       "random_state : int or RandomState\n",
       "    Pseudo-random number generator state used for random sampling.\n",
       "\n",
       "stratify : array-like or None (default is None)\n",
       "    If not None, data is split in a stratified fashion, using this as\n",
       "    the class labels.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "splitting : list, length=2 * len(arrays)\n",
       "    List containing train-test split of inputs.\n",
       "\n",
       "    .. versionadded:: 0.16\n",
       "        If the input is sparse, the output will be a\n",
       "        ``scipy.sparse.csr_matrix``. Else, output type is the same as the\n",
       "        input type.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> import numpy as np\n",
       ">>> from sklearn.model_selection import train_test_split\n",
       ">>> X, y = np.arange(10).reshape((5, 2)), range(5)\n",
       ">>> X\n",
       "array([[0, 1],\n",
       "       [2, 3],\n",
       "       [4, 5],\n",
       "       [6, 7],\n",
       "       [8, 9]])\n",
       ">>> list(y)\n",
       "[0, 1, 2, 3, 4]\n",
       "\n",
       ">>> X_train, X_test, y_train, y_test = train_test_split(\n",
       "...     X, y, test_size=0.33, random_state=42)\n",
       "...\n",
       ">>> X_train\n",
       "array([[4, 5],\n",
       "       [0, 1],\n",
       "       [6, 7]])\n",
       ">>> y_train\n",
       "[2, 0, 3]\n",
       ">>> X_test\n",
       "array([[2, 3],\n",
       "       [8, 9]])\n",
       ">>> y_test\n",
       "[1, 4]\n",
       "\u001b[0;31mFile:\u001b[0m      ~/work/batiskav/installs/anaconda3/lib/python3.5/site-packages/sklearn/model_selection/_split.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_test_split?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
